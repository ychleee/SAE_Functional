{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conditional vs Quantifier Analysis with SAE-Lens\n",
        "\n",
        "Using proven SAE implementation that actually works.\n",
        "\n",
        "**Setup**: Runtime â†’ Change runtime type â†’ T4 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install SAE-Lens and dependencies\n",
        "!pip install sae-lens transformer-lens circuitsvis\n",
        "!pip install --upgrade numpy  # Ensure compatibility\n",
        "\n",
        "print(\"âœ“ SAE-Lens installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone your repository for the dataset\n",
        "!rm -rf SAE_Functional\n",
        "!git clone https://github.com/ychleee/SAE_Functional.git\n",
        "%cd SAE_Functional\n",
        "\n",
        "# Mount Drive for results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "RESULTS_DIR = '/content/drive/MyDrive/sae_lens_results'\n",
        "!mkdir -p {RESULTS_DIR}\n",
        "print(f\"Results will be saved to: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "# Load the balanced dataset\n",
        "texts = []\n",
        "types = []\n",
        "\n",
        "dataset_file = 'data/processed/quantifier_conditional_balanced.csv'\n",
        "with open(dataset_file, 'r') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        texts.append(row['text'])\n",
        "        types.append(row['type'])\n",
        "\n",
        "types_array = np.array(types)\n",
        "type_counts = Counter(types)\n",
        "\n",
        "# Group counts\n",
        "conditionals = type_counts.get('conditional', 0)\n",
        "quantifiers = sum(v for k, v in type_counts.items() if 'universal' in k)\n",
        "controls = type_counts.get('control', 0)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET LOADED\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total: {len(texts)} sentences\")\n",
        "print(f\"  â€¢ Conditionals: {conditionals}\")\n",
        "print(f\"  â€¢ Quantifiers: {quantifiers}\")\n",
        "print(f\"  â€¢ Controls: {controls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Model with TransformerLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformer_lens import HookedTransformer\n",
        "import torch\n",
        "\n",
        "# Load model with TransformerLens (works better with SAE-Lens)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load Pythia-70m\n",
        "model = HookedTransformer.from_pretrained(\n",
        "    \"EleutherAI/pythia-70m\",\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Loaded model: {model.cfg.model_name}\")\n",
        "print(f\"  Hidden size: {model.cfg.d_model}\")\n",
        "print(f\"  Layers: {model.cfg.n_layers}\")\n",
        "print(f\"  Attention heads: {model.cfg.n_heads}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def extract_activations_transformer_lens(texts, model, layer=4, batch_size=32):\n",
        "    \"\"\"Extract activations using TransformerLens.\"\"\"\n",
        "    all_activations = []\n",
        "    \n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Extracting\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        \n",
        "        # Get activations at specific layer\n",
        "        _, cache = model.run_with_cache(\n",
        "            batch,\n",
        "            names_filter=lambda name: name == f\"blocks.{layer}.hook_resid_post\"\n",
        "        )\n",
        "        \n",
        "        # Get residual stream after layer\n",
        "        activations = cache[f\"blocks.{layer}.hook_resid_post\"]\n",
        "        \n",
        "        # Mean pool over sequence length\n",
        "        pooled = activations.mean(dim=1)\n",
        "        all_activations.append(pooled.cpu())\n",
        "    \n",
        "    return torch.cat(all_activations, dim=0)\n",
        "\n",
        "print(\"Extracting activations...\")\n",
        "activations = extract_activations_transformer_lens(texts, model, layer=4)\n",
        "print(f\"\\nâœ“ Activations shape: {activations.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train SAE with SAE-Lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sae_lens import SAE, SAEConfig\n",
        "\n",
        "# Configure SAE with proven settings\n",
        "cfg = SAEConfig(\n",
        "    # Architecture\n",
        "    d_in=model.cfg.d_model,  # Input dimension from model\n",
        "    d_sae=model.cfg.d_model * 16,  # 16x expansion (recommended)\n",
        "    \n",
        "    # Sparsity\n",
        "    k=32,  # Target ~32 active features\n",
        "    dead_feature_window=5000,  # Track dead features\n",
        "    dead_feature_threshold=1e-8,\n",
        "    \n",
        "    # Training\n",
        "    l1_coefficient=8e-5,  # Tuned for Pythia\n",
        "    lp_norm=1,  # L1 penalty\n",
        "    \n",
        "    # Advanced features\n",
        "    use_ghost_grads=True,  # Prevent dead features\n",
        "    normalize_sae_decoder=True,\n",
        "    scale_sparsity_penalty_by_decoder_norm=True,\n",
        "    \n",
        "    # Device\n",
        "    device=device,\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "print(\"SAE Configuration:\")\n",
        "print(f\"  Input dim: {cfg.d_in}\")\n",
        "print(f\"  SAE dim: {cfg.d_sae} ({cfg.d_sae // cfg.d_in}x expansion)\")\n",
        "print(f\"  Target sparsity: ~{cfg.k} features\")\n",
        "print(f\"  Ghost gradients: {cfg.use_ghost_grads}\")\n",
        "print(f\"  L1 coefficient: {cfg.l1_coefficient}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train SAE\n",
        "sae = SAE(cfg)\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = torch.optim.Adam(\n",
        "    sae.parameters(),\n",
        "    lr=3e-4,\n",
        "    betas=(0.9, 0.999)\n",
        ")\n",
        "\n",
        "# Training with proper sparsity\n",
        "print(\"\\nTraining SAE with ghost gradients...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "acts_tensor = activations.to(device)\n",
        "losses = []\n",
        "\n",
        "for step in range(5000):  # More steps for better convergence\n",
        "    # Forward pass\n",
        "    sae_out = sae(acts_tensor)\n",
        "    \n",
        "    # Compute loss (includes ghost gradient handling)\n",
        "    l_rec = (sae_out.sae_out - acts_tensor).pow(2).mean()\n",
        "    l_l1 = sae_out.feature_acts.abs().mean()\n",
        "    loss = l_rec + cfg.l1_coefficient * l_l1\n",
        "    \n",
        "    # Ghost gradients for dead features\n",
        "    if cfg.use_ghost_grads and step > 100:\n",
        "        # SAE-Lens handles this internally\n",
        "        dead_features = (sae_out.feature_acts.sum(0) == 0)\n",
        "        if dead_features.any():\n",
        "            # Re-initialize dead features\n",
        "            sae.handle_dead_features(dead_features)\n",
        "    \n",
        "    # Backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Normalize decoder\n",
        "    if cfg.normalize_sae_decoder:\n",
        "        sae.set_decoder_norm_to_unit_norm()\n",
        "    \n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    if step % 1000 == 0:\n",
        "        n_active = (sae_out.feature_acts > 0).float().sum(1).mean()\n",
        "        n_dead = (sae_out.feature_acts.sum(0) == 0).sum()\n",
        "        print(f\"Step {step}: Loss={loss:.4f} (Rec:{l_rec:.4f}, L1:{l_l1:.4f})\")\n",
        "        print(f\"         Active features: {n_active:.1f}, Dead: {n_dead}/{cfg.d_sae}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"âœ“ Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyze Feature Overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode all activations with trained SAE\n",
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "    sae_out = sae(acts_tensor)\n",
        "    features = sae_out.feature_acts.cpu().numpy()\n",
        "\n",
        "print(f\"Encoded features shape: {features.shape}\")\n",
        "print(f\"Sparsity: {(features > 0).mean():.3%} of features active\")\n",
        "print(f\"Features per sample: {(features > 0).sum(1).mean():.1f} Â± {(features > 0).sum(1).std():.1f}\")\n",
        "\n",
        "# This should show VARIABLE sparsity, not constant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate by type\n",
        "cond_mask = types_array == 'conditional'\n",
        "quant_mask = np.isin(types_array, [\n",
        "    'pure_universal', 'restricted_universal',\n",
        "    'negative_universal', 'generic_universal', 'any_universal'\n",
        "])\n",
        "ctrl_mask = types_array == 'control'\n",
        "\n",
        "cond_features = features[cond_mask]\n",
        "quant_features = features[quant_mask]\n",
        "ctrl_features = features[ctrl_mask]\n",
        "\n",
        "print(\"Features by type:\")\n",
        "print(f\"  Conditionals: {(cond_features > 0).sum(1).mean():.1f} active features\")\n",
        "print(f\"  Quantifiers: {(quant_features > 0).sum(1).mean():.1f} active features\")\n",
        "print(f\"  Controls: {(ctrl_features > 0).sum(1).mean():.1f} active features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find differential features\n",
        "def analyze_feature_overlap(cond_features, quant_features, ctrl_features, threshold=0.1):\n",
        "    \"\"\"Analyze which features are characteristic of each type.\"\"\"\n",
        "    \n",
        "    # Calculate activation frequency for each feature\n",
        "    cond_freq = (cond_features > 0).mean(0)\n",
        "    quant_freq = (quant_features > 0).mean(0)\n",
        "    ctrl_freq = (ctrl_features > 0).mean(0)\n",
        "    \n",
        "    # Find features more active in conditionals/quantifiers than controls\n",
        "    cond_specific = (cond_freq - ctrl_freq > threshold) & (cond_freq > quant_freq)\n",
        "    quant_specific = (quant_freq - ctrl_freq > threshold) & (quant_freq > cond_freq)\n",
        "    shared = (cond_freq - ctrl_freq > threshold) & (quant_freq - ctrl_freq > threshold)\n",
        "    \n",
        "    # Get indices\n",
        "    cond_indices = np.where(cond_specific)[0]\n",
        "    quant_indices = np.where(quant_specific)[0]\n",
        "    shared_indices = np.where(shared)[0]\n",
        "    \n",
        "    return {\n",
        "        'conditional_specific': cond_indices,\n",
        "        'quantifier_specific': quant_indices,\n",
        "        'shared': shared_indices,\n",
        "        'cond_freq': cond_freq,\n",
        "        'quant_freq': quant_freq,\n",
        "        'ctrl_freq': ctrl_freq\n",
        "    }\n",
        "\n",
        "# Analyze\n",
        "results = analyze_feature_overlap(cond_features, quant_features, ctrl_features)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE OVERLAP ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nðŸ“Š Characteristic Features:\")\n",
        "print(f\"  â€¢ Conditional-specific: {len(results['conditional_specific'])}\")\n",
        "print(f\"  â€¢ Quantifier-specific: {len(results['quantifier_specific'])}\")\n",
        "print(f\"  â€¢ Shared logical features: {len(results['shared'])}\")\n",
        "\n",
        "total = len(results['conditional_specific']) + len(results['quantifier_specific']) + len(results['shared'])\n",
        "if total > 0:\n",
        "    overlap_pct = len(results['shared']) / total * 100\n",
        "    print(f\"\\nðŸŽ¯ Overlap: {overlap_pct:.1f}% of characteristic features are shared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show top shared features\n",
        "if len(results['shared']) > 0:\n",
        "    print(\"\\nðŸ” Top Shared Features:\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Sort by average activation frequency\n",
        "    shared_scores = [\n",
        "        (idx, (results['cond_freq'][idx] + results['quant_freq'][idx]) / 2)\n",
        "        for idx in results['shared']\n",
        "    ]\n",
        "    shared_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    for i, (feat_idx, score) in enumerate(shared_scores[:10]):\n",
        "        print(f\"\\n{i+1}. Feature {feat_idx} (score: {score:.3f})\")\n",
        "        print(f\"   Conditional: {results['cond_freq'][feat_idx]:.2%} of sentences\")\n",
        "        print(f\"   Quantifier: {results['quant_freq'][feat_idx]:.2%} of sentences\")\n",
        "        print(f\"   Control: {results['ctrl_freq'][feat_idx]:.2%} of sentences\")\n",
        "        \n",
        "        # Find example sentences\n",
        "        cond_acts = cond_features[:, feat_idx]\n",
        "        quant_acts = quant_features[:, feat_idx]\n",
        "        \n",
        "        # Get top activating conditional\n",
        "        cond_texts = [t for t, ty in zip(texts, types_array) if ty == 'conditional']\n",
        "        if len(cond_texts) > 0 and cond_acts.max() > 0:\n",
        "            top_cond_idx = cond_acts.argmax()\n",
        "            print(f\"   Example (Cond): {cond_texts[top_cond_idx][:80]}...\")\n",
        "        \n",
        "        # Get top activating quantifier\n",
        "        quant_texts = [t for t, ty in zip(texts, types_array) if 'universal' in ty]\n",
        "        if len(quant_texts) > 0 and quant_acts.max() > 0:\n",
        "            top_quant_idx = quant_acts.argmax()\n",
        "            print(f\"   Example (Quant): {quant_texts[top_quant_idx][:80]}...\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ No shared features found.\")\n",
        "    print(\"This suggests conditionals and quantifiers use distinct representations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot sparsity distribution\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Sparsity by type\n",
        "axes[0].hist((cond_features > 0).sum(1), bins=30, alpha=0.5, label='Conditional', color='blue')\n",
        "axes[0].hist((quant_features > 0).sum(1), bins=30, alpha=0.5, label='Quantifier', color='green')\n",
        "axes[0].hist((ctrl_features > 0).sum(1), bins=30, alpha=0.5, label='Control', color='gray')\n",
        "axes[0].set_xlabel('Number of Active Features')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_title('Sparsity Distribution')\n",
        "axes[0].legend()\n",
        "\n",
        "# Feature activation frequencies\n",
        "axes[1].plot(results['cond_freq'], 'b-', alpha=0.5, label='Conditional')\n",
        "axes[1].plot(results['quant_freq'], 'g-', alpha=0.5, label='Quantifier')\n",
        "axes[1].plot(results['ctrl_freq'], 'gray', alpha=0.5, label='Control')\n",
        "axes[1].set_xlabel('Feature Index')\n",
        "axes[1].set_ylabel('Activation Frequency')\n",
        "axes[1].set_title('Feature Activation Patterns')\n",
        "axes[1].legend()\n",
        "axes[1].set_ylim([0, 1])\n",
        "\n",
        "# Overlap visualization\n",
        "categories = ['Cond-specific', 'Shared', 'Quant-specific']\n",
        "counts = [\n",
        "    len(results['conditional_specific']),\n",
        "    len(results['shared']),\n",
        "    len(results['quantifier_specific'])\n",
        "]\n",
        "colors = ['blue', 'yellow', 'green']\n",
        "axes[2].bar(categories, counts, color=colors)\n",
        "axes[2].set_ylabel('Number of Features')\n",
        "axes[2].set_title('Feature Overlap Summary')\n",
        "\n",
        "plt.suptitle('SAE-Lens Feature Analysis', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/sae_lens_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nâœ“ Visualization saved to {RESULTS_DIR}/sae_lens_analysis.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Save model\n",
        "torch.save(sae.state_dict(), f'{RESULTS_DIR}/sae_lens_model.pt')\n",
        "\n",
        "# Save results\n",
        "results_json = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'dataset': {\n",
        "        'total': len(texts),\n",
        "        'conditionals': int(conditionals),\n",
        "        'quantifiers': int(quantifiers),\n",
        "        'controls': int(controls)\n",
        "    },\n",
        "    'sae_config': {\n",
        "        'd_in': cfg.d_in,\n",
        "        'd_sae': cfg.d_sae,\n",
        "        'k': cfg.k,\n",
        "        'l1_coefficient': cfg.l1_coefficient,\n",
        "        'use_ghost_grads': cfg.use_ghost_grads\n",
        "    },\n",
        "    'results': {\n",
        "        'conditional_specific': len(results['conditional_specific']),\n",
        "        'quantifier_specific': len(results['quantifier_specific']),\n",
        "        'shared': len(results['shared']),\n",
        "        'overlap_percentage': overlap_pct if total > 0 else 0,\n",
        "        'avg_active_features': (features > 0).sum(1).mean().item(),\n",
        "        'sparsity': (features > 0).mean().item()\n",
        "    },\n",
        "    'shared_features': results['shared'].tolist()[:20]  # Top 20 shared features\n",
        "}\n",
        "\n",
        "with open(f'{RESULTS_DIR}/results.json', 'w') as f:\n",
        "    json.dump(results_json, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… ANALYSIS COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nResults saved to: {RESULTS_DIR}\")\n",
        "print(\"\\nKey findings:\")\n",
        "print(f\"  â€¢ Sparsity achieved: {(features > 0).sum(1).mean():.1f} features (variable!)\")\n",
        "print(f\"  â€¢ Feature overlap: {len(results['shared'])} shared features\")\n",
        "print(f\"  â€¢ Overlap percentage: {overlap_pct:.1f}%\" if total > 0 else \"  â€¢ No differential features found\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}