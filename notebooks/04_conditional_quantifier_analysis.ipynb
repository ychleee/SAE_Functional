{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Overlap Analysis: Conditionals vs Universal Quantifiers\n",
        "\n",
        "This notebook tests the hypothesis that conditional sentences (if-then) and universal quantifiers (all, every, any) share underlying logical features in language models.\n",
        "\n",
        "**Key Question**: Do \"All birds fly\" and \"If something is a bird, then it flies\" activate similar features?\n",
        "\n",
        "**Setup**: Runtime â†’ Change runtime type â†’ T4 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi | grep \"Tesla\" || echo \"âš ï¸ No GPU found - please enable GPU in Runtime settings\"\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q transformers accelerate einops matplotlib-venn scipy scikit-learn statsmodels\n",
        "\n",
        "print(\"âœ“ Packages installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!rm -rf SAE_Functional\n",
        "!git clone https://github.com/ychleee/SAE_Functional.git\n",
        "%cd SAE_Functional\n",
        "\n",
        "# Mount Google Drive for results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "RESULTS_DIR = '/content/drive/MyDrive/sae_quantifier_analysis'\n",
        "!mkdir -p {RESULTS_DIR}\n",
        "print(f\"Results will be saved to: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Quantifier-Conditional Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Load dataset\n",
        "texts = []\n",
        "types = []\n",
        "has_quantifier = []\n",
        "\n",
        "with open('data/processed/quantifier_conditional_dataset.csv', 'r') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        texts.append(row['text'])\n",
        "        types.append(row['type'])\n",
        "        has_quantifier.append(row['has_quantifier'] == 'True')\n",
        "\n",
        "# Statistics\n",
        "type_counts = Counter(types)\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total sentences: {len(texts)}\")\n",
        "print(\"\\nBreakdown by type:\")\n",
        "for t, count in sorted(type_counts.items()):\n",
        "    print(f\"  â€¢ {t:20s}: {count:4d}\")\n",
        "\n",
        "# Show samples\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAMPLE SENTENCES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Show one of each type\n",
        "shown_types = set()\n",
        "for i, (text, t) in enumerate(zip(texts, types)):\n",
        "    if t not in shown_types:\n",
        "        print(f\"\\n[{t}]\")\n",
        "        print(f\"  {text}\")\n",
        "        shown_types.add(t)\n",
        "        if len(shown_types) >= min(5, len(type_counts)):\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract Activations from Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load model\n",
        "model_name = \"EleutherAI/pythia-70m\"\n",
        "print(f\"Loading {model_name}...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"âœ“ Model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_activations(texts, batch_size=32, max_samples=1200):\n",
        "    \"\"\"Extract activations from language model.\"\"\"\n",
        "    texts = texts[:max_samples]\n",
        "    activations = []\n",
        "    \n",
        "    print(f\"Extracting activations for {len(texts)} sentences...\")\n",
        "    \n",
        "    for i in tqdm(range(0, len(texts), batch_size)):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        \n",
        "        # Tokenize\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        ).to(device)\n",
        "        \n",
        "        # Get hidden states\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, output_hidden_states=True)\n",
        "            hidden = outputs.hidden_states[-1]  # Last layer\n",
        "            \n",
        "            # Mean pooling over tokens\n",
        "            mask = inputs.attention_mask.unsqueeze(-1)\n",
        "            pooled = (hidden * mask).sum(1) / mask.sum(1)\n",
        "            \n",
        "            activations.append(pooled.cpu())\n",
        "    \n",
        "    return torch.cat(activations, dim=0)\n",
        "\n",
        "# Extract activations\n",
        "activations = extract_activations(texts, batch_size=32, max_samples=1200)\n",
        "print(f\"\\nâœ“ Activations shape: {activations.shape}\")\n",
        "\n",
        "# Convert types to numpy array for easier indexing\n",
        "types_array = np.array(types[:len(activations)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Sparse Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SparseAutoencoder(nn.Module):\n",
        "    \"\"\"Sparse Autoencoder for feature discovery.\"\"\"\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim=2048, sparsity_coeff=0.01):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim, bias=False)\n",
        "        self.sparsity_coeff = sparsity_coeff\n",
        "        \n",
        "        # Tie weights\n",
        "        self.decoder.weight = nn.Parameter(self.encoder.weight.t())\n",
        "        \n",
        "        # Initialize\n",
        "        nn.init.xavier_uniform_(self.encoder.weight)\n",
        "        nn.init.zeros_(self.encoder.bias)\n",
        "    \n",
        "    def encode(self, x):\n",
        "        return torch.relu(self.encoder(x))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        code = self.encode(x)\n",
        "        recon = self.decoder(code)\n",
        "        return recon, code\n",
        "\n",
        "# Create SAE\n",
        "input_dim = activations.shape[1]\n",
        "hidden_dim = 2048  # Larger for more fine-grained features\n",
        "sae = SparseAutoencoder(input_dim, hidden_dim, sparsity_coeff=0.01).to(device)\n",
        "\n",
        "print(f\"SAE Architecture: {input_dim} â†’ {hidden_dim} â†’ {input_dim}\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in sae.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training setup\n",
        "optimizer = optim.Adam(sae.parameters(), lr=0.001)\n",
        "acts_tensor = activations.to(device)\n",
        "\n",
        "# Training loop\n",
        "print(\"Training SAE...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(100):\n",
        "    # Forward pass\n",
        "    recon, code = sae(acts_tensor)\n",
        "    \n",
        "    # Losses\n",
        "    recon_loss = nn.functional.mse_loss(recon, acts_tensor)\n",
        "    sparse_loss = sae.sparsity_coeff * code.abs().mean()\n",
        "    total_loss = recon_loss + sparse_loss\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    losses.append(total_loss.item())\n",
        "    \n",
        "    if epoch % 20 == 0:\n",
        "        active = (code > 0).float().mean().item()\n",
        "        print(f\"Epoch {epoch:3d}: Loss={total_loss:.4f} (R:{recon_loss:.4f} S:{sparse_loss:.4f}) Active={active:.3f}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"âœ“ Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analyze Feature Overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import analysis module\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from analyze_quantifier_overlap import FeatureOverlapAnalyzer\n",
        "\n",
        "# Create analyzer\n",
        "analyzer = FeatureOverlapAnalyzer(sae, device)\n",
        "\n",
        "# Encode all sentences\n",
        "print(\"Encoding sentences to sparse features...\")\n",
        "codes_by_type, all_codes = analyzer.encode_sentences(activations.numpy(), types_array)\n",
        "\n",
        "print(f\"\\nâœ“ Encoded {len(all_codes)} sentences into {all_codes.shape[1]} features\")\n",
        "print(f\"  â€¢ Conditionals: {len(codes_by_type['conditional'])} sentences\")\n",
        "print(f\"  â€¢ Quantifiers: {len(codes_by_type['quantifier'])} sentences\")\n",
        "print(f\"  â€¢ Controls: {len(codes_by_type['control'])} sentences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify characteristic features\n",
        "print(\"Identifying characteristic features...\")\n",
        "features = analyzer.identify_characteristic_features(codes_by_type, threshold=0.05)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE DISCOVERY RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nðŸ“Š Feature Categories:\")\n",
        "print(f\"  â€¢ Conditional-specific features: {len(features['conditional_specific'])}\")\n",
        "print(f\"  â€¢ Quantifier-specific features: {len(features['quantifier_specific'])}\")\n",
        "print(f\"  â€¢ SHARED LOGICAL FEATURES: {len(features['shared'])} â­\")\n",
        "print(f\"  â€¢ Control features: {len(features['control'])}\")\n",
        "\n",
        "# Calculate overlap percentage\n",
        "total_relevant = (len(features['conditional_specific']) + \n",
        "                 len(features['quantifier_specific']) + \n",
        "                 len(features['shared']))\n",
        "if total_relevant > 0:\n",
        "    overlap_pct = len(features['shared']) / total_relevant * 100\n",
        "    print(f\"\\nðŸŽ¯ Overlap: {overlap_pct:.1f}% of relevant features are shared\")\n",
        "    print(f\"   Jaccard Index: {features['overlap_stats']['jaccard_index']:.3f}\")\n",
        "\n",
        "# Show top shared features\n",
        "if len(features['shared']) > 0:\n",
        "    print(\"\\nðŸ” Top Shared Features (encode logical relationships):\")\n",
        "    for i, feat_idx in enumerate(features['shared'][:10]):\n",
        "        cond_act = features['overlap_stats']['conditional_mean'][feat_idx]\n",
        "        quant_act = features['overlap_stats']['quantifier_mean'][feat_idx]\n",
        "        ctrl_act = features['overlap_stats']['control_mean'][feat_idx]\n",
        "        print(f\"   {i+1}. Feature {feat_idx}: Cond={cond_act:.3f}, Quant={quant_act:.3f}, Ctrl={ctrl_act:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Statistical Significance Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform statistical tests\n",
        "print(\"Running statistical tests...\")\n",
        "stats_results = analyzer.statistical_tests(codes_by_type)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STATISTICAL ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nðŸ“ˆ Hypothesis Testing:\")\n",
        "print(f\"  â€¢ H0: Conditionals and quantifiers have identical feature distributions\")\n",
        "print(f\"  â€¢ H1: They have different but overlapping distributions\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Results:\")\n",
        "print(f\"  â€¢ Features with significant differences: {len(stats_results['significant_features'])}\")\n",
        "print(f\"  â€¢ KS test statistic: {stats_results['ks_test']['statistic']:.4f}\")\n",
        "print(f\"  â€¢ KS test p-value: {stats_results['ks_test']['p_value']:.2e}\")\n",
        "\n",
        "# Effect sizes\n",
        "large_effects = np.where(np.abs(stats_results['effect_sizes']) > 0.8)[0]\n",
        "medium_effects = np.where((np.abs(stats_results['effect_sizes']) > 0.5) & \n",
        "                         (np.abs(stats_results['effect_sizes']) <= 0.8))[0]\n",
        "\n",
        "print(f\"\\nðŸ“ Effect Sizes (Cohen's d):\")\n",
        "print(f\"  â€¢ Large effects (|d| > 0.8): {len(large_effects)} features\")\n",
        "print(f\"  â€¢ Medium effects (0.5 < |d| â‰¤ 0.8): {len(medium_effects)} features\")\n",
        "\n",
        "if stats_results['ks_test']['p_value'] < 0.001:\n",
        "    print(\"\\nâœ… Conclusion: Statistically significant difference in distributions\")\n",
        "    print(\"   BUT substantial feature overlap suggests shared logical processing\")\n",
        "else:\n",
        "    print(\"\\nâœ… Conclusion: Similar feature distributions\")\n",
        "    print(\"   Strong evidence for shared logical representations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Create Venn diagram\n",
        "print(\"Creating Venn diagram...\")\n",
        "venn_fig = analyzer.create_venn_diagram(features)\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "venn_fig.savefig(f'{RESULTS_DIR}/venn_diagram.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ“ Venn diagram saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create t-SNE visualization\n",
        "print(\"Creating t-SNE visualization (this may take a minute)...\")\n",
        "tsne_fig = analyzer.create_tsne_visualization(all_codes, types_array)\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "tsne_fig.savefig(f'{RESULTS_DIR}/tsne_plot.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ“ t-SNE plot saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create heatmaps\n",
        "print(\"Creating feature heatmaps...\")\n",
        "heatmap_fig = analyzer.create_heatmap(features)\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "heatmap_fig.savefig(f'{RESULTS_DIR}/heatmaps.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ“ Heatmaps saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Similarity matrix\n",
        "print(\"Computing similarity matrix...\")\n",
        "similarity, patterns = analyzer.compute_similarity_matrix(codes_by_type)\n",
        "\n",
        "# Plot similarity matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(similarity, \n",
        "            xticklabels=['Conditional', 'Quantifier', 'Control'],\n",
        "            yticklabels=['Conditional', 'Quantifier', 'Control'],\n",
        "            annot=True, fmt='.3f', cmap='YlOrRd', \n",
        "            vmin=0, vmax=1, square=True, cbar_kws={'label': 'Cosine Similarity'})\n",
        "ax.set_title('Feature Pattern Similarity Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save\n",
        "fig.savefig(f'{RESULTS_DIR}/similarity_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ“ Similarity matrix saved\")\n",
        "\n",
        "print(f\"\\nðŸ”— Conditional-Quantifier Similarity: {similarity[0, 1]:.3f}\")\n",
        "print(f\"   Conditional-Control Similarity: {similarity[0, 2]:.3f}\")\n",
        "print(f\"   Quantifier-Control Similarity: {similarity[1, 2]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Feature Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find example sentences for top shared features\n",
        "print(\"=\"*60)\n",
        "print(\"EXAMPLE SENTENCES FOR SHARED FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if len(features['shared']) > 0:\n",
        "    # Take top 3 shared features\n",
        "    for feat_idx in features['shared'][:3]:\n",
        "        print(f\"\\nðŸ“ Feature {feat_idx} (Shared Logical Feature)\")\n",
        "        print(\"-\"*40)\n",
        "        \n",
        "        # Get activations for this feature\n",
        "        feat_acts = all_codes[:, feat_idx]\n",
        "        \n",
        "        # Find top examples from conditionals\n",
        "        cond_mask = types_array == 'conditional'\n",
        "        cond_acts = feat_acts[cond_mask]\n",
        "        cond_texts = [t for t, m in zip(texts[:len(types_array)], cond_mask) if m]\n",
        "        \n",
        "        if len(cond_acts) > 0:\n",
        "            top_cond = np.argsort(cond_acts)[-2:][::-1]\n",
        "            print(\"\\n  Conditionals:\")\n",
        "            for idx in top_cond:\n",
        "                if idx < len(cond_texts):\n",
        "                    print(f\"    [{cond_acts[idx]:.2f}] {cond_texts[idx][:80]}\")\n",
        "        \n",
        "        # Find top examples from quantifiers\n",
        "        quant_mask = np.isin(types_array, ['pure_universal', 'restricted_universal', \n",
        "                                           'negative_universal', 'generic_universal', \n",
        "                                           'any_universal'])\n",
        "        quant_acts = feat_acts[quant_mask]\n",
        "        quant_texts = [t for t, m in zip(texts[:len(types_array)], quant_mask) if m]\n",
        "        quant_types = [t for t, m in zip(types_array, quant_mask) if m]\n",
        "        \n",
        "        if len(quant_acts) > 0:\n",
        "            top_quant = np.argsort(quant_acts)[-2:][::-1]\n",
        "            print(\"\\n  Universal Quantifiers:\")\n",
        "            for idx in top_quant:\n",
        "                if idx < len(quant_texts):\n",
        "                    q_type = quant_types[idx].replace('_', ' ')\n",
        "                    print(f\"    [{quant_acts[idx]:.2f}] [{q_type}] {quant_texts[idx][:60]}\")\n",
        "else:\n",
        "    print(\"No shared features found with current threshold.\")\n",
        "    print(\"This might indicate distinct processing mechanisms.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Generate Final Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive report\n",
        "report = analyzer.generate_report(codes_by_type, features, stats_results)\n",
        "print(report)\n",
        "\n",
        "# Save report\n",
        "with open(f'{RESULTS_DIR}/analysis_report.txt', 'w') as f:\n",
        "    f.write(report)\n",
        "print(f\"\\nâœ“ Report saved to {RESULTS_DIR}/analysis_report.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Save Model and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Save model\n",
        "torch.save({\n",
        "    'model_state': sae.state_dict(),\n",
        "    'input_dim': input_dim,\n",
        "    'hidden_dim': hidden_dim,\n",
        "    'sparsity_coeff': sae.sparsity_coeff\n",
        "}, f'{RESULTS_DIR}/sae_model.pt')\n",
        "print(f\"âœ“ Model saved\")\n",
        "\n",
        "# Save analysis results\n",
        "results = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'dataset': {\n",
        "        'total_sentences': len(texts),\n",
        "        'conditionals': int(type_counts.get('conditional', 0)),\n",
        "        'quantifiers': sum(v for k, v in type_counts.items() if 'universal' in k),\n",
        "        'controls': int(type_counts.get('control', 0))\n",
        "    },\n",
        "    'features': {\n",
        "        'conditional_specific': len(features['conditional_specific']),\n",
        "        'quantifier_specific': len(features['quantifier_specific']),\n",
        "        'shared': len(features['shared']),\n",
        "        'jaccard_index': float(features['overlap_stats']['jaccard_index'])\n",
        "    },\n",
        "    'statistical_tests': {\n",
        "        'ks_statistic': float(stats_results['ks_test']['statistic']),\n",
        "        'ks_p_value': float(stats_results['ks_test']['p_value']),\n",
        "        'significant_features': int(len(stats_results['significant_features']))\n",
        "    },\n",
        "    'similarity': {\n",
        "        'conditional_quantifier': float(similarity[0, 1]),\n",
        "        'conditional_control': float(similarity[0, 2]),\n",
        "        'quantifier_control': float(similarity[1, 2])\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(f'{RESULTS_DIR}/results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(f\"âœ“ Results saved\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ‰ ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nAll results saved to: {RESULTS_DIR}\")\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"  â€¢ venn_diagram.png - Feature overlap visualization\")\n",
        "print(\"  â€¢ tsne_plot.png - Sentence clustering in feature space\")\n",
        "print(\"  â€¢ heatmaps.png - Feature activation patterns\")\n",
        "print(\"  â€¢ similarity_matrix.png - Type similarity analysis\")\n",
        "print(\"  â€¢ analysis_report.txt - Comprehensive text report\")\n",
        "print(\"  â€¢ sae_model.pt - Trained SAE model\")\n",
        "print(\"  â€¢ results.json - Numerical results\")\n",
        "print(\"\\nðŸ“¥ Download from Google Drive when complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}